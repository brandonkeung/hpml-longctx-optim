{
  "run_meta": {
    "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
    "model": "mistralai/Mistral-7B-Instruct-v0.3",
    "attn": "sdpa",
    "dtype": "torch.bfloat16",
    "device_map": "auto",
    "contexts": [
      8192,
      16384
    ],
    "n_samples": 503,
    "batch_size": 50,
    "max_new_tokens": 64,
    "timestamp": "20251117-030159"
  },
  "ctx_summaries": [
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "n_requests": 11,
      "latency_ms_p50": 11701.58,
      "latency_ms_p95": 11701.58,
      "ttft_ms_p50": 5827.44,
      "ttft_ms_p95": 5827.44,
      "ms_per_token_p50": 182.84,
      "ms_per_token_p95": 182.84,
      "tok_per_s_p50": 5.47,
      "tok_per_s_p95": 5.47,
      "decode_ms_p50": 5874.13,
      "decode_ms_p95": 5874.13,
      "ms_per_token_decode_p50": 91.78,
      "ms_per_token_decode_p95": 91.78,
      "tok_per_s_decode_p50": 10.9,
      "tok_per_s_decode_p95": 10.9,
      "peak_gpu_mem_gb_p95": 19.43,
      "em_rate": 0.6667
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "n_requests": 11,
      "latency_ms_p50": 27691.14,
      "latency_ms_p95": 27691.14,
      "ttft_ms_p50": 16197.9,
      "ttft_ms_p95": 16197.9,
      "ms_per_token_p50": 432.67,
      "ms_per_token_p95": 432.67,
      "tok_per_s_p50": 2.31,
      "tok_per_s_p95": 2.31,
      "decode_ms_p50": 11493.24,
      "decode_ms_p95": 11493.24,
      "ms_per_token_decode_p50": 179.58,
      "ms_per_token_decode_p95": 179.58,
      "tok_per_s_decode_p50": 5.57,
      "tok_per_s_decode_p95": 5.57,
      "peak_gpu_mem_gb_p95": 25.72,
      "em_rate": 0.6667
    }
  ],
  "rows": [
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.61 GiB is free. Including non-PyTorch memory, this process h",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 6.74 GiB is free. Including non-PyTorch memory, this process h",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 6.74 GiB is free. Including non-PyTorch memory, this process h",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 6.74 GiB is free. Including non-PyTorch memory, this process h",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 6.74 GiB is free. Including non-PyTorch memory, this process h",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 6.74 GiB is free. Including non-PyTorch memory, this process h",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 6.74 GiB is free. Including non-PyTorch memory, this process h",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 6.74 GiB is free. Including non-PyTorch memory, this process h",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 10.94 GiB. GPU 0 has a total capacity of 47.40 GiB of which 6.74 GiB is free. Including non-PyTorch memory, this process h",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 3,
      "latency_ms_total": 11701.58,
      "ttft_ms": 5827.44,
      "avg_gen_tokens": 64.0,
      "tok_per_s": 5.47,
      "ms_per_token": 182.84,
      "peak_gpu_mem_gb": 19.43,
      "em_hits_in_batch": 2,
      "success": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 12.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 12.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 12.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 12.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 12.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 12.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 12.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 12.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 12.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 12.50 GiB. GPU 0 has a total capacity of 47.40 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 3,
      "latency_ms_total": 27691.14,
      "ttft_ms": 16197.9,
      "avg_gen_tokens": 64.0,
      "tok_per_s": 2.31,
      "ms_per_token": 432.67,
      "peak_gpu_mem_gb": 25.72,
      "em_hits_in_batch": 4,
      "success": true
    }
  ],
  "summary": {
    "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251117-030159",
    "model": "mistralai/Mistral-7B-Instruct-v0.3",
    "attn": "sdpa",
    "total_samples": 503,
    "batch_size": 50,
    "contexts": [
      8192,
      16384
    ],
    "oom_count": 20,
    "EM": 0.007952286282306162,
    "timestamp": "20251117-030159"
  }
}