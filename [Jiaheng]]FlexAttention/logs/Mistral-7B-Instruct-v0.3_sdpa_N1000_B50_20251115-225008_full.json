{
  "run_meta": {
    "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
    "model": "mistralai/Mistral-7B-Instruct-v0.3",
    "attn": "sdpa",
    "dtype": "torch.bfloat16",
    "device_map": "auto",
    "contexts": [
      4096,
      8192,
      16384,
      32768
    ],
    "n_samples": 1000,
    "batch_size": 50,
    "max_new_tokens": 64,
    "timestamp": "20251115-225008"
  },
  "ctx_summaries": [
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "n_requests": 20,
      "latency_ms_p50": 24104.96,
      "latency_ms_p95": 25767.84,
      "ttft_ms_p50": 19881.83,
      "ttft_ms_p95": 20724.3,
      "ms_per_token_p50": 1576.96,
      "ms_per_token_p95": 1698.59,
      "tok_per_s_p50": 0.64,
      "tok_per_s_p95": 0.69,
      "decode_ms_p50": 4223.13,
      "decode_ms_p95": 5043.54,
      "ms_per_token_decode_p50": 270.0,
      "ms_per_token_decode_p95": 283.73,
      "tok_per_s_decode_p50": 3.72,
      "tok_per_s_decode_p95": 3.9,
      "peak_gpu_mem_gb_p95": 41.77,
      "em_rate": 0.47
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "n_requests": 20,
      "latency_ms_p50": 24721.06,
      "latency_ms_p95": 26907.43,
      "ttft_ms_p50": 19453.12,
      "ttft_ms_p95": 19880.65,
      "ms_per_token_p50": 1379.5,
      "ms_per_token_p95": 1681.23,
      "tok_per_s_p50": 0.77,
      "tok_per_s_p95": 0.94,
      "decode_ms_p50": 5267.94,
      "decode_ms_p95": 7026.78,
      "ms_per_token_decode_p50": 266.34,
      "ms_per_token_decode_p95": 276.63,
      "tok_per_s_decode_p50": 3.76,
      "tok_per_s_decode_p95": 3.91,
      "peak_gpu_mem_gb_p95": 40.46,
      "em_rate": 0.48
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "n_requests": 20,
      "latency_ms_p50": 24703.48,
      "latency_ms_p95": 26879.0,
      "ttft_ms_p50": 19435.3,
      "ttft_ms_p95": 19851.81,
      "ms_per_token_p50": 1378.72,
      "ms_per_token_p95": 1680.77,
      "tok_per_s_p50": 0.77,
      "tok_per_s_p95": 0.94,
      "decode_ms_p50": 5268.19,
      "decode_ms_p95": 7027.2,
      "ms_per_token_decode_p50": 266.35,
      "ms_per_token_decode_p95": 276.65,
      "tok_per_s_decode_p50": 3.76,
      "tok_per_s_decode_p95": 3.91,
      "peak_gpu_mem_gb_p95": 40.46,
      "em_rate": 0.48
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "n_requests": 20,
      "latency_ms_p50": 24714.9,
      "latency_ms_p95": 26908.34,
      "ttft_ms_p50": 19444.6,
      "ttft_ms_p95": 19877.1,
      "ms_per_token_p50": 1378.99,
      "ms_per_token_p95": 1680.2,
      "tok_per_s_p50": 0.77,
      "tok_per_s_p95": 0.94,
      "decode_ms_p50": 5270.29,
      "decode_ms_p95": 7031.24,
      "ms_per_token_decode_p50": 266.43,
      "ms_per_token_decode_p95": 276.8,
      "tok_per_s_decode_p50": 3.76,
      "tok_per_s_decode_p95": 3.91,
      "peak_gpu_mem_gb_p95": 40.46,
      "em_rate": 0.48
    }
  ],
  "rows": [
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 4.42 GiB. GPU 0 has a total capacity of 47.40 GiB of which 629.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.01 GiB. GPU 0 has a total capacity of 47.40 GiB of which 435.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "latency_ms_total": 25952.61,
      "ttft_ms": 20817.91,
      "avg_gen_tokens": 18.0,
      "tok_per_s": 0.69,
      "ms_per_token": 1441.81,
      "peak_gpu_mem_gb": 41.91,
      "em_hits_in_batch": 21,
      "success": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.98 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.57 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.72 GiB. GPU 0 has a total capacity of 47.40 GiB of which 369.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 4.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 4.77 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.59 GiB. GPU 0 has a total capacity of 47.40 GiB of which 167.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 77.25 MiB is free. Including non-PyTorch memory, this process h",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.07 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.07 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.12 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "latency_ms_total": 22257.31,
      "ttft_ms": 18945.75,
      "avg_gen_tokens": 13.0,
      "tok_per_s": 0.58,
      "ms_per_token": 1712.1,
      "peak_gpu_mem_gb": 39.16,
      "em_hits_in_batch": 47,
      "success": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.54 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 4.54 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.29 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.59 GiB. GPU 0 has a total capacity of 47.40 GiB of which 621.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacity of 47.40 GiB of which 327.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.56 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.48 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.11 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.84 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.80 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 4096,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.09 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 4.42 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.08 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.01 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.22 GiB. GPU 0 has a total capacity of 47.40 GiB of which 871.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.98 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.45 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.72 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.97 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 4.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.00 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.59 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.57 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 211.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.35 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "latency_ms_total": 27150.36,
      "ttft_ms": 19928.15,
      "avg_gen_tokens": 26.0,
      "tok_per_s": 0.96,
      "ms_per_token": 1044.24,
      "peak_gpu_mem_gb": 40.53,
      "em_hits_in_batch": 69,
      "success": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "latency_ms_total": 22291.76,
      "ttft_ms": 18978.09,
      "avg_gen_tokens": 13.0,
      "tok_per_s": 0.58,
      "ms_per_token": 1714.75,
      "peak_gpu_mem_gb": 39.16,
      "em_hits_in_batch": 95,
      "success": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.54 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 4.54 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.29 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.59 GiB. GPU 0 has a total capacity of 47.40 GiB of which 621.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacity of 47.40 GiB of which 327.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.56 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.48 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.11 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.84 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.80 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 8192,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.09 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 4.42 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.08 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.01 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.22 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.98 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.45 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.72 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.97 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 4.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.00 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.59 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.57 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 211.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.35 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "latency_ms_total": 27120.73,
      "ttft_ms": 19898.09,
      "avg_gen_tokens": 26.0,
      "tok_per_s": 0.96,
      "ms_per_token": 1043.1,
      "peak_gpu_mem_gb": 40.53,
      "em_hits_in_batch": 117,
      "success": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "latency_ms_total": 22286.24,
      "ttft_ms": 18972.51,
      "avg_gen_tokens": 13.0,
      "tok_per_s": 0.58,
      "ms_per_token": 1714.33,
      "peak_gpu_mem_gb": 39.16,
      "em_hits_in_batch": 143,
      "success": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.54 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 4.54 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.29 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.59 GiB. GPU 0 has a total capacity of 47.40 GiB of which 621.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacity of 47.40 GiB of which 327.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.56 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.48 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.11 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.84 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.80 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 16384,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.09 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 4.42 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.08 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.01 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.22 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.05 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.98 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.45 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.72 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.97 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 4.87 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.00 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.59 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.57 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.28 GiB. GPU 0 has a total capacity of 47.40 GiB of which 211.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.16 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.35 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "latency_ms_total": 27152.05,
      "ttft_ms": 19925.15,
      "avg_gen_tokens": 26.0,
      "tok_per_s": 0.96,
      "ms_per_token": 1044.31,
      "peak_gpu_mem_gb": 40.53,
      "em_hits_in_batch": 165,
      "success": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "latency_ms_total": 22277.74,
      "ttft_ms": 18964.05,
      "avg_gen_tokens": 13.0,
      "tok_per_s": 0.58,
      "ms_per_token": 1713.67,
      "peak_gpu_mem_gb": 39.16,
      "em_hits_in_batch": 191,
      "success": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.54 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 4.54 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.29 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.59 GiB. GPU 0 has a total capacity of 47.40 GiB of which 621.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacity of 47.40 GiB of which 327.25 MiB is free. Including non-PyTorch memory, this process ",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 2.95 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.56 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.48 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.11 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.84 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.80 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    },
    {
      "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "attn": "sdpa",
      "context_tokens": 32768,
      "batch_size": 50,
      "error": "CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.09 GiB is free. Including non-PyTorch memory, this process ha",
      "success": false,
      "oom": true
    }
  ],
  "summary": {
    "run_id": "Mistral-7B-Instruct-v0.3_sdpa_N1000_B50_20251115-225008",
    "model": "mistralai/Mistral-7B-Instruct-v0.3",
    "attn": "sdpa",
    "total_samples": 1000,
    "batch_size": 50,
    "contexts": [
      4096,
      8192,
      16384,
      32768
    ],
    "oom_count": 72,
    "EM": 0.191,
    "timestamp": "20251115-225008"
  }
}