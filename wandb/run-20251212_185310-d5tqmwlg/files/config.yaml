_wandb:
    value:
        cli_version: 0.23.1
        e:
            zeu1sevjimn1mw715p5g7led4x4j4l1v:
                codePath: longbench_kv_eval.py
                codePathLocal: longbench_kv_eval.py
                cpu_count: 96
                cpu_count_logical: 192
                cudaVersion: "12.9"
                disk:
                    /:
                        total: "74906075136"
                        used: "48325308416"
                email: bk2951@columbia.edu
                executable: /insomnia001/home/bk2951/hpml-longctx-optim/.venv/bin/python
                git:
                    commit: f843e8e254ec6920cf157d8a224ecf12a9613158
                    remote: https://github.com/brandonkeung/hpml-longctx-optim.git
                gpu: NVIDIA RTX A6000
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 10752
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX A6000
                      uuid: GPU-94295ea9-27c6-be9d-c2a1-4d0a69e6d12e
                host: ins080
                memory:
                    total: "1081451159552"
                os: Linux-5.14.0-362.8.1.el9_3.x86_64-x86_64-with-glibc2.34
                program: /insomnia001/home/bk2951/hpml-longctx-optim/longbench_kv_eval.py
                python: CPython 3.9.18
                root: /insomnia001/home/bk2951/hpml-longctx-optim
                slurm:
                    cluster_name: insomnia
                    conf: /etc/slurm/slurm.conf
                    cpus_on_node: "2"
                    gpus_on_node: "1"
                    gtids: "0"
                    job_account: edu
                    job_cpus_per_node: "2"
                    job_end_time: "1765584733"
                    job_gid: "500"
                    job_group: user
                    job_id: "5816871"
                    job_name: bash
                    job_nodelist: ins080
                    job_num_nodes: "1"
                    job_partition: short
                    job_qos: interactive
                    job_start_time: "1765577533"
                    job_uid: "560037"
                    job_user: bk2951
                    jobid: "5816871"
                    launch_node_ipaddr: 10.197.95.250
                    localid: "0"
                    nnodes: "1"
                    nodeid: "0"
                    nodelist: ins080
                    nprocs: "1"
                    ntasks: "1"
                    oom_kill_step: "0"
                    prio_process: "0"
                    procid: "0"
                    pty_port: "44583"
                    pty_win_col: "118"
                    pty_win_row: "26"
                    srun_comm_host: 10.197.95.250
                    srun_comm_port: "45999"
                    step_gpus: "4"
                    step_id: "0"
                    step_launcher_port: "45999"
                    step_nodelist: ins080
                    step_num_nodes: "1"
                    step_num_tasks: "1"
                    step_tasks_per_node: "1"
                    stepid: "0"
                    submit_dir: /insomnia001/home/bk2951/hpml-longctx-optim
                    submit_host: 2402-login-002
                    task_pid: "3822710"
                    tasks_per_node: "1"
                    topology_addr: ins080
                    topology_addr_pattern: node
                    umask: "0027"
                startedAt: "2025-12-12T23:53:10.194584Z"
                writerId: zeu1sevjimn1mw715p5g7led4x4j4l1v
        m: []
        python_version: 3.9.18
        t:
            "1":
                - 1
                - 11
                - 49
                - 51
                - 71
            "2":
                - 1
                - 11
                - 49
                - 51
                - 71
            "3":
                - 2
                - 13
                - 16
            "4": 3.9.18
            "5": 0.23.1
            "6": 4.57.3
            "12": 0.23.1
            "13": linux-x86_64
attn_impl:
    value: flash2
batch_size:
    value: 1
contexts:
    value:
        - 2048
        - 4096
        - 8192
        - 16384
        - 32768
dataset_id:
    value: zai-org/LongBench-v2
device_map:
    value: auto
dtype:
    value: torch.bfloat16
keep_ratio:
    value: 0.7
kv_mode:
    value: none
max_new_tokens:
    value: 64
model_id:
    value: Qwen/Qwen1.5-1.8B-Chat
n_samples:
    value: 50
prune_after:
    value: 512
skip_layers:
    value:
        - 0
        - 1
split:
    value: train[:50]
use_4bit:
    value: false
