_wandb:
    value:
        cli_version: 0.23.1
        e:
            iqpb477h6xhz6vwhlduf7078looktqyo:
                codePath: longbench_kv_eval.py
                codePathLocal: longbench_kv_eval.py
                cpu_count: 96
                cpu_count_logical: 192
                cudaVersion: "12.9"
                disk:
                    /:
                        total: "74968989696"
                        used: "43538464768"
                email: bk2951@columbia.edu
                executable: /insomnia001/home/bk2951/hpml-longctx-optim/.venv/bin/python
                git:
                    commit: e157ea0a9e912cb25bb5f3db3c2ef6b41422f50a
                    remote: https://github.com/brandonkeung/hpml-longctx-optim.git
                gpu: NVIDIA RTX A6000
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 10752
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX A6000
                      uuid: GPU-6e7e0253-4b85-9ea2-f1d9-c912e5e4d7b2
                host: ins088
                memory:
                    total: "1081451167744"
                os: Linux-5.14.0-362.8.1.el9_3.x86_64-x86_64-with-glibc2.34
                program: /insomnia001/home/bk2951/hpml-longctx-optim/longbench_kv_eval.py
                python: CPython 3.9.18
                root: /insomnia001/home/bk2951/hpml-longctx-optim
                slurm:
                    cluster_name: insomnia
                    conf: /etc/slurm/slurm.conf
                    cpus_on_node: "2"
                    gpus_on_node: "1"
                    gtids: "0"
                    job_account: edu
                    job_cpus_per_node: "2"
                    job_end_time: "1765598164"
                    job_gid: "500"
                    job_group: user
                    job_id: "5819885"
                    job_name: bash
                    job_nodelist: ins088
                    job_num_nodes: "1"
                    job_partition: short
                    job_qos: interactive
                    job_start_time: "1765590964"
                    job_uid: "560037"
                    job_user: bk2951
                    jobid: "5819885"
                    launch_node_ipaddr: 10.197.95.250
                    localid: "0"
                    nnodes: "1"
                    nodeid: "0"
                    nodelist: ins088
                    nprocs: "1"
                    ntasks: "1"
                    oom_kill_step: "0"
                    prio_process: "0"
                    procid: "0"
                    pty_port: "35183"
                    pty_win_col: "86"
                    pty_win_row: "26"
                    srun_comm_host: 10.197.95.250
                    srun_comm_port: "40869"
                    step_gpus: "7"
                    step_id: "0"
                    step_launcher_port: "40869"
                    step_nodelist: ins088
                    step_num_nodes: "1"
                    step_num_tasks: "1"
                    step_tasks_per_node: "1"
                    stepid: "0"
                    submit_dir: /insomnia001/home/bk2951/hpml-longctx-optim
                    submit_host: 2402-login-002
                    task_pid: "1127568"
                    tasks_per_node: "1"
                    topology_addr: ins088
                    topology_addr_pattern: node
                    umask: "0027"
                startedAt: "2025-12-13T02:37:17.297301Z"
                writerId: iqpb477h6xhz6vwhlduf7078looktqyo
        m: []
        python_version: 3.9.18
        t:
            "1":
                - 1
                - 11
                - 49
                - 51
                - 71
            "2":
                - 1
                - 11
                - 49
                - 51
                - 71
            "3":
                - 2
                - 13
                - 16
            "4": 3.9.18
            "5": 0.23.1
            "6": 4.57.3
            "12": 0.23.1
            "13": linux-x86_64
attn_impl:
    value: flash2
batch_size:
    value: 1
contexts:
    value:
        - 2048
        - 4096
        - 8192
        - 16384
        - 32768
dataset_id:
    value: zai-org/LongBench-v2
device_map:
    value: auto
dtype:
    value: torch.bfloat16
keep_ratio:
    value: 0.7
kv_mode:
    value: none
max_new_tokens:
    value: 64
model_id:
    value: mistralai/Mistral-7B-Instruct-v0.3
n_samples:
    value: 50
prune_after:
    value: 512
skip_layers:
    value:
        - 0
        - 1
split:
    value: train[:50]
use_4bit:
    value: false
